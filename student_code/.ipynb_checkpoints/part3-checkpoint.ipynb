{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0197814",
   "metadata": {},
   "source": [
    "# Student Information\n",
    "Please fill in your details below:\n",
    "Student Name: [Your Name]\n",
    "Student ID: [Your ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4b7d8",
   "metadata": {},
   "source": [
    "# Part 3: Small Object Segmentation and Evaluation\n",
    "In this section, you will evaluate small object segmentation performance and apply strategies to improve it. You will work with the car, lane-marking, and pedestrian classes. Additionally, you will compare small-object metrics and report any improvements made after applying fine-tuning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867535d9-0d85-4982-bf77-33da5caac016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XMG\\AppData\\Local\\Temp\\ipykernel_16696\\3241707190.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import camvidLoader\n",
    "\n",
    "# Set device for GPU usage\n",
    "device = 'cuda'\n",
    "\n",
    "# Load the pretrained model\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "\n",
    "# Set the path to the sunny dataset\n",
    "data_root = '../CamVid/sunny'\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = camvidLoader(root=data_root, split='test', is_aug=False, img_size=[384, 384], is_pytorch_transform=True)\n",
    "\n",
    "# Number of classes in the dataset (fixed to 14 for this project)\n",
    "num_classes = 14\n",
    "\n",
    "# Class labels dictionary (used for mapping predicted labels to actual class names)\n",
    "class_labels_dict = {\n",
    "    \"Sky\": 0, \"Building\": 1, \"Pole\": 2, \"Road\": 3, \"LaneMarking\": 4, \"SideWalk\": 5, \n",
    "    \"Pavement\": 6, \"Tree\": 7, \"SignSymbol\": 8, \"Fence\": 9, \"Car_Bus\": 10, \"Pedestrian\": 11, \n",
    "    \"Bicyclist\": 12, \"Unlabelled\": 13\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a7399",
   "metadata": {},
   "source": [
    "# Task C1: Evaluate Object-Level Metrics for Small Objects\n",
    "In this task, you will use the `compute_object_level_stats_percentile` function to evaluate the performance of the model on small objects (car, lane-marking, and pedestrian). You will compare the small-object metrics with large-object metrics and demonstrate how segmentation of small objects is a challenge.\n",
    "\n",
    "### Key Steps:\n",
    "- Use `compute_object_level_stats_percentile` for the classes `Car_Bus`, `LaneMarking`, and `Pedestrian`.\n",
    "- Compare small-object metrics with large-object metrics.\n",
    "- Display five images showing ground-truth segmentation vs. model predictions, highlighting missed or partially segmented small objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d8d67b-f4c0-4668-b986-3e8b7e5d5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_obj_metric import compute_object_level_stats_percentile\n",
    "# Task C1: Please read and understand our evaluation code function compute_object_level_stats_percentile\n",
    "# and use Run compute_object_level_stats_percentile for car, lane-mark, and pedestrian classes.\n",
    "# Compare small-object metrics with large-object metrics to validate that segmentation of small objects is indeed a challenge for the car, lane-marker, and pedestrian classes.\n",
    "# Show at least five images with ground-truth segmentations vs. model prediction results highlighting missed or partially segmented small objects.\n",
    "\n",
    "# Example: \n",
    "# gt_mask_list is an numpy array of shape (140, 384, 384), indicating 140 groundtruth segmentation mask of 384x384 (data type is int64)\n",
    "# pred_mask_list is an numpy array of shape (140, 384, 384), indicating 140 prediction segmentation mask of 384x384 (data type is int64)\n",
    "# print(compute_object_level_stats_percentile(np.array(gt_mask),np.array(pred_mask), 'LaneMarking', iou_threshold=0.25, size_percentile=50)) # lanemarking\n",
    "# wil output\n",
    "#Metric                        Small Objects       Large Objects       \n",
    "#======================================================================\n",
    "#Class Name                    LaneMarking         \n",
    "#Size Threshold (pixels)       4.00                \n",
    "#======================================================================\n",
    "#Total Ground Truths           3620                3904                \n",
    "#Total Predicted               3051                3089                \n",
    "#Precision                     0.0960              0.4618              \n",
    "#Recall                        0.0796              0.3809              \n",
    "#F1 Score                      0.0870              0.4175              \n",
    "#False Positives (FP)          2711                1733                \n",
    "#False Negatives (FN)          3332                2417                \n",
    "#True Positives (TP)           288                 1487                \n",
    "#======================================================================\n",
    "#(0.0960320106702202, 0.07955801104972156, 0.08702220874330649, 0.4618012422360105, 0.3808913934426132, 0.4174620998943009)\n",
    "# Please include this output in your notebook and copy this table to your Assessment Task 2 Worksheet as well (this table will not be counted towards word limit or page limit)\n",
    "# Please do the evaluation similar for other class like:\n",
    "# compute_object_level_stats_percentile(np.array(gt_mask),np.array(pred_mask), 'Car_Bus', iou_threshold=0.25, size_percentile=50)\n",
    "# compute_object_level_stats_percentile(np.array(gt_mask),np.array(pred_mask), 'Pedestrian', iou_threshold=0.25, size_percentile=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eeba3a",
   "metadata": {},
   "source": [
    "# Task C2: Improve Small Object Segmentation\n",
    "After identifying weaknesses in small-object segmentation, you will choose at least one strategy (or more) to improve the model's performance in detecting small objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2b24c7-b683-4aae-b029-82b4422116a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task C2: After identifying weaknesses in small-object segmentation, choose at least one of the strategies\n",
    "# (implementing two strategies may yield higher marks) to improve small object segmentation performance\n",
    "# Please see the coursework document for detailed instructions\n",
    "# Clearly mark or comment your changes in the jupyter notebook\n",
    "# Submit all the necessary code to the learning mall to ensure your notebook result is reproducible\n",
    "# and briefly mention modifications in your assessment worksheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8d72",
   "metadata": {},
   "source": [
    "# Task C3: Recompute Metrics After Improvements\n",
    "After applying your chosen strategies for improving small object segmentation, you will recompute overall metrics (such as global accuracy and mean IoU). You will also check the small-object metrics again to verify the improvements made for car, pedestrian, and lane-marking classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387c55b0-2fe4-4c6b-b64c-2a8eb7b1637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task C3: After improving your model for small object segmentation\n",
    "# 1.Recompute overall metrics (global accuracy, mean IoU) as you did for the original model.\n",
    "# 2.Use compute_object_level_stats_percentile again to see how your improvements affect small-object metrics for cars, pedestrians, and lane-markings.\n",
    "# 3. Compare (precision_small, recall_small, F1_small) before and after your changes.\n",
    "# 4. If you employed multiple improvements or strategies, clearly explain how each individual approach/strategy contributed to the enhancement of small-object segmentation \n",
    "# based on experimental evaluation results (for example, the small-object metrics, mean IoU or global accuracy) and/or your analysis.\n",
    "# 5. Note any trade-offs, such as slightly lower performance on large objects or other classes.\n",
    "# 6. Show side-by-side images (ground truth vs. predicted segmentation) before and after your chosen strategies, demonstrating improvements in small-object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea85ae0-1532-4476-9cc1-7e285bcdc248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
