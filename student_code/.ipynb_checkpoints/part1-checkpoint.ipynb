{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18917f1d",
   "metadata": {},
   "source": [
    "# Student Information\n",
    "Please fill in your details below:\n",
    "Student Name: [Your Name]\n",
    "Student ID: [Your ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b400b76",
   "metadata": {},
   "source": [
    "# Part 1: Evaluate the Pretrained Model on Sunny Test Images\n",
    "In this section, you will load the pretrained model and the dataset. You will then prepare the model and dataset for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea44509-8ac0-461c-86c4-9b65bf820cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import camvidLoader\n",
    "import numpy as np\n",
    "\n",
    "# Set device to 'cuda' for GPU usage or 'cpu' for CPU\n",
    "device = 'cuda'  # Can be set to \"cuda\" if you have a GPU\n",
    "\n",
    "# Load the pretrained U-Net model\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "\n",
    "# Set the path to your dataset\n",
    "data_root = '../CamVid/sunny'\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = camvidLoader(root=data_root, split='test', is_aug=False, img_size=[384, 384], is_pytorch_transform=True)\n",
    "\n",
    "# Number of classes in the dataset (fixed to 14 for this project)\n",
    "num_classes = 14\n",
    "\n",
    "# Class labels dictionary (used for mapping predicted labels to actual class names)\n",
    "class_labels_dict = {\n",
    "    \"Sky\": 0, \"Building\": 1, \"Pole\": 2, \"Road\": 3, \"LaneMarking\": 4, \"SideWalk\": 5, \n",
    "    \"Pavement\": 6, \"Tree\": 7, \"SignSymbol\": 8, \"Fence\": 9, \"Car_Bus\": 10, \"Pedestrian\": 11, \n",
    "    \"Bicyclist\": 12, \"Unlabelled\": 13\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2bd956",
   "metadata": {},
   "source": [
    "# Task: Implement Evaluation Metric Functions\n",
    "In this task, you need to implement two evaluation metrics for the model's performance: Global Accuracy and Intersection over Union (IoU). These metrics will be used to assess the quality of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89341862-9009-4ab9-aa26-cbdb5223d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global accuracy function\n",
    "def global_accuracy_metric(y_true, y_pred):\n",
    "    pass  # Implement this function\n",
    "\n",
    "# Define IoU metric function\n",
    "def IoU_metric(y_true, y_pred):\n",
    "    pass  # Implement this function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b1428",
   "metadata": {},
   "source": [
    "# Task: Write Your Testing Loop\n",
    "Here, you will implement the testing loop where the model makes predictions on the test data and evaluates its performance using the metrics defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b517d6b-9a79-490f-9728-3eeba2010282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your testing loop here\n",
    "# This is where you will run the model on the test data and compute the evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21adf91",
   "metadata": {},
   "source": [
    "# Task: Calculate Global Image Accuracy and Per-Class Accuracy\n",
    "In this task, you will compute the global accuracy and per-class accuracy for the entire test dataset. These metrics will help you evaluate the overall performance of the model and how well it handles each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cee43e-b3f1-4b79-8639-4007e3592318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement code to calculate global image accuracy and per-class accuracy here\n",
    "# This step will involve comparing the predictions with the ground truth labels for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e019b47",
   "metadata": {},
   "source": [
    "# Task: Image Ranking Based on Accuracy Scores\n",
    "In this task, you will rank the images in the dataset based on their global accuracy and mean IoU scores. You should select a few examples where the model performs exceptionally well and others where it struggles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c5092-12e1-467c-847e-5fdbb97a20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement image ranking code here\n",
    "# Rank images based on global image accuracy and mean IoU scores, and select examples for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
