{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32b18b8",
   "metadata": {},
   "source": [
    "# Student Information\n",
    "Please fill in your details below:\n",
    "Student Name: [Your Name]\n",
    "Student ID: [Your ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ae4fe",
   "metadata": {},
   "source": [
    "# Part 2: Evaluate and Fine-Tune the Pretrained Model on Darker Cloudy Dataset\n",
    "In this section, you will evaluate the pretrained model on a darker, cloudy dataset and fine-tune it to improve performance. You will experiment with different loss functions and your choosen model fine-tuning strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c6e87b0-f10c-49b6-8341-73cd943ffbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XMG\\AppData\\Local\\Temp\\ipykernel_24312\\1693390631.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataset import camvidLoader\n",
    "import numpy as np\n",
    "\n",
    "# Set device to 'cuda' for GPU usage or 'cpu' for CPU\n",
    "device = 'cuda'  # Can be set to \"cuda\" if you have a GPU\n",
    "\n",
    "# Load the pretrained U-Net model\n",
    "unet = torch.load('camvid_sunny_model.pt', map_location=torch.device(device))\n",
    "\n",
    "# Set the path to your cloudy dataset\n",
    "data_root = '../CamVid/cloudy'\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = camvidLoader(root=data_root, split='test', is_aug=False, img_size=[384, 384], is_pytorch_transform=True)\n",
    "\n",
    "# Number of classes in the dataset (fixed to 14 for this project)\n",
    "num_classes = 14\n",
    "\n",
    "# Class labels dictionary (used for mapping predicted labels to actual class names)\n",
    "class_labels_dict = {\n",
    "    \"Sky\": 0, \"Building\": 1, \"Pole\": 2, \"Road\": 3, \"LaneMarking\": 4, \"SideWalk\": 5, \n",
    "    \"Pavement\": 6, \"Tree\": 7, \"SignSymbol\": 8, \"Fence\": 9, \"Car_Bus\": 10, \"Pedestrian\": 11, \n",
    "    \"Bicyclist\": 12, \"Unlabelled\": 13\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a371551",
   "metadata": {},
   "source": [
    "# Task B1: Evaluate Pretrained Cloudy Dataset Performance on the Test Set\n",
    "In this task, you will evaluate the performance of the pretrained model on the cloudy test dataset. You will report the global image accuracy and per-class Intersection over Union (IoU) results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad48dc3-3c2d-44a8-8928-68edd8811e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pretrained model on the cloudy dataset\n",
    "# Report global image accuracy and per-class IoU results here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57a070",
   "metadata": {},
   "source": [
    "# Task B2: Fine-Tuning the Model\n",
    "In this task, you will experiment with different loss functions and fine-tuning techniques. You will try using Dice loss, Cross-Entropy (CE) loss, and a combination of both, and observe their impact on performance. Additionally, you will experiment with data augmentation, optimizers, and learning rate schedulers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c186577-8c2a-4bd3-b9b4-8fc342356593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B2 (1) (2): Implement the model fine-tuning code\n",
    "# Experiment with different loss functions: Dice, CE, and Dice + CE\n",
    "# See how these affect the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800fc57c-08b6-4136-a4e6-5e96380ebc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B2 (3): Try additional fine-tuning techniques\n",
    "# Implement at least one additional technique of your choices.\n",
    "# For example, experiment with different data augmentation, alternative optimizers, and learning-rate schedulers. Consider freezing some layers and fine-tuning others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ecfa6",
   "metadata": {},
   "source": [
    "# Task B2/B3: Evaluate the Model During and After Fine-Tuning\n",
    "During the fine-tuning process, you will track the training and validation loss curves to determine the best fine-tuned model. You should highlight the performance of different methods and loss functions, showing how they affect the global accuracy and per-class IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ad926f-f705-4ae2-8d7b-dac49c4327f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B2/B3: Plot training/validation loss curves and evaluate fine-tuned model\n",
    "# During fine-tuning, plot the loss curves for training and validation.\n",
    "# Compare the performance of different strategies by printing global accuracy and per-class IoU results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf543b0",
   "metadata": {},
   "source": [
    "# Task B3: Evaluate Cloudy Dataset Performance After Fine-Tuning\n",
    "After fine-tuning the model, you will evaluate its performance on the test set. Again, report the global image accuracy and per-class IoU results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73140057-b9d5-4386-9363-80bed7cc549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B3: Evaluate the performance of the best fine-tuned model on the cloudy test dataset\n",
    "# Report global image accuracy and per-class IoU results after fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb2f3a-291f-4166-9bfa-02348103929e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
